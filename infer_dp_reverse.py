"""
æ¨¡å‹å…·æœ‰reverseçš„èƒ½åŠ› \\
infer_dp.pyå’Œinfer_dp_reverse.pyç›®å‰éƒ½è¿˜æ²¡æœ‰relativeçš„èƒ½åŠ› \\
æ•²å…¥å›è½¦, æœºå™¨å°±ä¼šåœä¸‹æ¥, ç„¶åreverseæ‰§è¡Œ
"""

import sys
import os
import pathlib
import hydra
from omegaconf import OmegaConf
import torch
import numpy as np
from termcolor import cprint
import copy
import threading
from real_sensors import RealRobotEnv
ROOT_DIR = str(pathlib.Path(__file__).parent)
sys.path.append(ROOT_DIR)
os.chdir(ROOT_DIR)
from reactive_diffusion_policy.policy.diffusion_unet_image_policy import DiffusionUnetImagePolicy

# ç›‘æ§ç”¨æˆ·è¾“å…¥
import queue
import time
import select

def user_input_listener(input_queue):
    """åå°çº¿ç¨‹ï¼Œç›‘å¬ç”¨æˆ·æŒ‰å›è½¦"""
    while True:
        # ä½¿ç”¨selectç›‘å¬æ˜¯å¦æœ‰è¾“å…¥ï¼ˆéé˜»å¡ï¼‰
        if sys.stdin in select.select([sys.stdin], [], [], 0)[0]:
            _ = sys.stdin.readline()  # è¯»å–æ•´è¡Œï¼Œä½†ä¸ä½¿ç”¨å†…å®¹
            if input_queue.empty():
                input_queue.put("ENTER")
        time.sleep(0.1)  # é¿å…å ç”¨CPU


input_key_list = ['left_wrist_img', 'left_robot_tcp_pose', 'left_robot_gripper_width']

class RealWorldDPInfer:
    def __init__(self, cfg: OmegaConf):
        # =========== Load configuration ===========
        self.cfg = cfg
        self.device = torch.device(cfg.device)

        # =========== Load checkpoint ===========
        cprint(f"Loading checkpoint from: {cfg.inference.ckpt_path}", "yellow")
        payload = torch.load(cfg.inference.ckpt_path, map_location=self.device)
        train_cfg = payload['cfg']
        
        # The policy configuration is saved within the checkpoint
        policy_cfg = train_cfg.policy
        self.env = RealRobotEnv(
                                n_obs_steps=policy_cfg.n_obs_steps,
                                pca_load_dir=cfg.inference.pca_path,
                                robo_ip=cfg.inference.robot_ip)
        
        # Instantiate the policy
        self.policy: DiffusionUnetImagePolicy = hydra.utils.instantiate(policy_cfg)
        if cfg.training.use_ema:
            self.ema_model = copy.deepcopy(self.policy)
            self.policy = self.ema_model
        
        # Load the model weights
        self.policy.load_state_dict(payload['state_dicts']['model'])
        
        
        # Move policy to the correct device and set to evaluation mode
        self.policy.to(self.device)
        self.policy.eval()

        # =========== Initialize observation buffer ===========
        self.n_obs_steps = policy_cfg.n_obs_steps
        # Get the observation keys from the training config's shape_meta
        self.key_to_shape = train_cfg.shape_meta['obs']


    def run(self):
        """ä¸»æ¨ç†å¾ªç¯"""
        print("Start inference loop...")
        input_dict = dict()


        input_queue = queue.Queue()  # ç”¨äºæ¥æ”¶ç”¨æˆ·è¾“å…¥äº‹ä»¶
        # å¯åŠ¨ç‹¬ç«‹çº¿ç¨‹ç›‘å¬é”®ç›˜è¾“å…¥
        listener_thread = threading.Thread(target=user_input_listener, args=(input_queue,), daemon=True)
        listener_thread.start()
        print("å¯åŠ¨ç›‘å¬çº¿ç¨‹, é”®å…¥å›è½¦å°±å¯ä»¥è®©æœºå™¨æ‰§è¡Œreverse")

        try:
            rossub_thread = threading.Thread(target=self.env.ros_thread, daemon=True)
            rossub_thread.start()
            step_count = 0
            should_reverse = False
            reverse_hoziron = self.policy.reverse_length # å¾€å›èµ°å‡ æ­¥
            while True:
                obs = self.env.get_obs()
                if obs is None:
                    continue
                else:
                # å°†å¤šå¸§è§‚æµ‹æ•°æ®å †å æˆä¸€ä¸ªæ‰¹æ¬¡
                    obs_processed = {
                        key: torch.from_numpy(np.stack([o[key] for o in obs])).unsqueeze(0).to(self.device)
                        for key in obs[0].keys()
                    }
                    # Data Processing
                    for key in obs_processed.keys():
                        if 'img' in key:
                            obs_processed[key] = obs_processed[key].permute(0, 1, 4, 2, 3)  # BNHWC -> BNCHW
                            obs_processed[key] = obs_processed[key].float() / 255.0
                    for key in input_key_list:
                        input_dict[key] = obs_processed[key]
                    
                    # Data Processing
                    # ä½¿ç”¨æ¨¡å‹è¿›è¡ŒåŠ¨ä½œé¢„æµ‹
                    with torch.no_grad():
                        action_dict = self.policy.predict_action(input_dict)

                    # æå–åŠ¨ä½œåºåˆ—
                    action_sequence = action_dict['action'].detach().cpu().numpy()[0]
                    action_reverse_sequence = action_dict['action_reverse'].detach().cpu().numpy()[0]
                    
                    # ä¾æ¬¡æ‰§è¡ŒåŠ¨ä½œåºåˆ—ä¸­çš„æ¯ä¸ªåŠ¨ä½œ
                    for i in range(min(self.cfg.n_action_steps, len(action_sequence))):
                        action_step = action_sequence[i]
                        if not input_queue.empty():
                            event = input_queue.get()
                            if event == "ENTER":
                                print("ğŸš¨ æ£€æµ‹åˆ°ç”¨æˆ·æŒ‰ä¸‹å›è½¦, è¿›å…¥ reverse æ¨¡å¼!å…ˆæš‚åœä¸¤ç§’, ç„¶åreverseæ‰§è¡Œ")
                                should_reverse = True
                                time.sleep(2)  # æš‚åœ2ç§’
                                break

                        self.env.execute_action(action_step)
                    
                    if should_reverse:
                        for i in range(min(reverse_hoziron, len(action_reverse_sequence))):
                            reverse_action_step = action_reverse_sequence[i]
                            self.env.execute_action(reverse_action_step)
                            print(f"å¾€å›èµ°å“Ÿ")
                        should_reverse = False
                        print(f"reverseæ‰§è¡Œå®Œæ¯•, å°†ç»§ç»­æ­£å‘æ‰§è¡Œ")
                    
                    step_count += 1
                    if step_count >= self.env.max_steps:
                        print(f"å·²æ‰§è¡Œ{50}æ­¥ï¼Œæ¨ç†å¾ªç¯ç»“æŸã€‚")
                        break  # æˆ–è€…ç”¨ break è·³å‡º while True

        except KeyboardInterrupt:
            print("æ¨ç†è¢«ç”¨æˆ·ä¸­æ–­ã€‚")
        finally:
            print("ç¨‹åºç»“æŸã€‚")

@hydra.main(
    version_base=None,
    config_path="./reactive_diffusion_policy/config",
    config_name="dp_infer"
)
def main(cfg: OmegaConf):
    # Create the inference runner and start the loop
    OmegaConf.set_struct(cfg, False)
    cfg.inference = {
        'ckpt_path': cfg.load_ckpt_path,
        'pca_path': cfg.load_pca_path,
        'robot_ip': '192.168.1.239'
    }
    OmegaConf.set_struct(cfg, True)
    runner = RealWorldDPInfer(cfg)
    runner.run()

if __name__ == "__main__":
    main()
 