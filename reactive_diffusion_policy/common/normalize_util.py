from reactive_diffusion_policy.model.common.normalizer import SingleFieldLinearNormalizer
from reactive_diffusion_policy.common.pytorch_util import dict_apply, dict_apply_reduce, dict_apply_split
import numpy as np
import torch


def get_range_normalizer_from_stat(stat, output_max=1, output_min=-1, range_eps=1e-7):
    # -1, 1 normalization
    input_max = stat['max']
    input_min = stat['min']
    input_range = input_max - input_min
    ignore_dim = input_range < range_eps
    input_range[ignore_dim] = output_max - output_min
    scale = (output_max - output_min) / input_range
    offset = output_min - scale * input_min
    offset[ignore_dim] = (output_max + output_min) / 2 - input_min[ignore_dim]

    return SingleFieldLinearNormalizer.create_manual(
        scale=scale,
        offset=offset,
        input_stats_dict=stat
    )

def get_image_range_normalizer():
    scale = np.array([2], dtype=np.float32)
    offset = np.array([-1], dtype=np.float32)
    stat = {
        'min': np.array([0], dtype=np.float32),
        'max': np.array([1], dtype=np.float32),
        'mean': np.array([0.5], dtype=np.float32),
        'std': np.array([np.sqrt(1/12)], dtype=np.float32)
    }
    return SingleFieldLinearNormalizer.create_manual(
        scale=scale,
        offset=offset,
        input_stats_dict=stat
    )

def get_identity_normalizer_from_stat(stat):
    scale = np.ones_like(stat['min'])
    offset = np.zeros_like(stat['min'])
    return SingleFieldLinearNormalizer.create_manual(
        scale=scale,
        offset=offset,
        input_stats_dict=stat
    )

def robomimic_abs_action_normalizer_from_stat(stat, rotation_transformer):
    result = dict_apply_split(
        stat, lambda x: {
            'pos': x[...,:3],
            'rot': x[...,3:6],
            'gripper': x[...,6:]
    })

    def get_pos_param_info(stat, output_max=1, output_min=-1, range_eps=1e-7):
        # -1, 1 normalization
        input_max = stat['max']
        input_min = stat['min']
        input_range = input_max - input_min
        ignore_dim = input_range < range_eps
        input_range[ignore_dim] = output_max - output_min
        scale = (output_max - output_min) / input_range
        offset = output_min - scale * input_min
        offset[ignore_dim] = (output_max + output_min) / 2 - input_min[ignore_dim]

        return {'scale': scale, 'offset': offset}, stat

    def get_rot_param_info(stat):
        example = rotation_transformer.forward(stat['mean'])
        scale = np.ones_like(example)
        offset = np.zeros_like(example)
        info = {
            'max': np.ones_like(example),
            'min': np.full_like(example, -1),
            'mean': np.zeros_like(example),
            'std': np.ones_like(example)
        }
        return {'scale': scale, 'offset': offset}, info
    
    def get_gripper_param_info(stat):
        example = stat['max']
        scale = np.ones_like(example)
        offset = np.zeros_like(example)
        info = {
            'max': np.ones_like(example),
            'min': np.full_like(example, -1),
            'mean': np.zeros_like(example),
            'std': np.ones_like(example)
        }
        return {'scale': scale, 'offset': offset}, info

    pos_param, pos_info = get_pos_param_info(result['pos'])
    rot_param, rot_info = get_rot_param_info(result['rot'])
    gripper_param, gripper_info = get_gripper_param_info(result['gripper'])

    param = dict_apply_reduce(
        [pos_param, rot_param, gripper_param], 
        lambda x: np.concatenate(x,axis=-1))
    info = dict_apply_reduce(
        [pos_info, rot_info, gripper_info], 
        lambda x: np.concatenate(x,axis=-1))

    return SingleFieldLinearNormalizer.create_manual(
        scale=param['scale'],
        offset=param['offset'],
        input_stats_dict=info
    )


def robomimic_abs_action_only_normalizer_from_stat(stat):
    result = dict_apply_split(
        stat, lambda x: {
            'pos': x[...,:3],
            'other': x[...,3:]
    })

    def get_pos_param_info(stat, output_max=1, output_min=-1, range_eps=1e-7):
        # -1, 1 normalization
        input_max = stat['max']
        input_min = stat['min']
        input_range = input_max - input_min
        ignore_dim = input_range < range_eps
        input_range[ignore_dim] = output_max - output_min
        scale = (output_max - output_min) / input_range
        offset = output_min - scale * input_min
        offset[ignore_dim] = (output_max + output_min) / 2 - input_min[ignore_dim]

        return {'scale': scale, 'offset': offset}, stat

    
    def get_other_param_info(stat):
        example = stat['max']
        scale = np.ones_like(example)
        offset = np.zeros_like(example)
        info = {
            'max': np.ones_like(example),
            'min': np.full_like(example, -1),
            'mean': np.zeros_like(example),
            'std': np.ones_like(example)
        }
        return {'scale': scale, 'offset': offset}, info

    pos_param, pos_info = get_pos_param_info(result['pos'])
    other_param, other_info = get_other_param_info(result['other'])

    param = dict_apply_reduce(
        [pos_param, other_param], 
        lambda x: np.concatenate(x,axis=-1))
    info = dict_apply_reduce(
        [pos_info, other_info], 
        lambda x: np.concatenate(x,axis=-1))

    return SingleFieldLinearNormalizer.create_manual(
        scale=param['scale'],
        offset=param['offset'],
        input_stats_dict=info
    )


def robomimic_abs_action_only_dual_arm_normalizer_from_stat(stat):
    Da = stat['max'].shape[-1]
    Dah = Da // 2
    result = dict_apply_split(
        stat, lambda x: {
            'pos0': x[...,:3],
            'other0': x[...,3:Dah],
            'pos1': x[...,Dah:Dah+3],
            'other1': x[...,Dah+3:]
    })

    def get_pos_param_info(stat, output_max=1, output_min=-1, range_eps=1e-7):
        # -1, 1 normalization
        input_max = stat['max']
        input_min = stat['min']
        input_range = input_max - input_min
        ignore_dim = input_range < range_eps
        input_range[ignore_dim] = output_max - output_min
        scale = (output_max - output_min) / input_range
        offset = output_min - scale * input_min
        offset[ignore_dim] = (output_max + output_min) / 2 - input_min[ignore_dim]

        return {'scale': scale, 'offset': offset}, stat

    
    def get_other_param_info(stat):
        example = stat['max']
        scale = np.ones_like(example)
        offset = np.zeros_like(example)
        info = {
            'max': np.ones_like(example),
            'min': np.full_like(example, -1),
            'mean': np.zeros_like(example),
            'std': np.ones_like(example)
        }
        return {'scale': scale, 'offset': offset}, info

    pos0_param, pos0_info = get_pos_param_info(result['pos0'])
    pos1_param, pos1_info = get_pos_param_info(result['pos1'])
    other0_param, other0_info = get_other_param_info(result['other0'])
    other1_param, other1_info = get_other_param_info(result['other1'])

    param = dict_apply_reduce(
        [pos0_param, other0_param, pos1_param, other1_param], 
        lambda x: np.concatenate(x,axis=-1))
    info = dict_apply_reduce(
        [pos0_info, other0_info, pos1_info, other1_info], 
        lambda x: np.concatenate(x,axis=-1))

    return SingleFieldLinearNormalizer.create_manual(
        scale=param['scale'],
        offset=param['offset'],
        input_stats_dict=info
    )


def array_to_stats(arr: np.ndarray):
    # Check for NaN or Inf values
    if np.any(np.isnan(arr)) or np.any(np.isinf(arr)):
        print(f"[WARNING] array_to_stats: Found NaN or Inf in array with shape {arr.shape}")
        print(f"  NaN count: {np.sum(np.isnan(arr))}")
        print(f"  Inf count: {np.sum(np.isinf(arr))}")
        print(f"  Min: {np.nanmin(arr) if not np.all(np.isnan(arr)) else 'all NaN'}")
        print(f"  Max: {np.nanmax(arr) if not np.all(np.isnan(arr)) else 'all NaN'}")
        # Replace NaN/Inf with safe values
        arr = np.nan_to_num(arr, nan=0.0, posinf=1e6, neginf=-1e6)
    
    stat = {
        'min': np.min(arr, axis=0),
        'max': np.max(arr, axis=0),
        'mean': np.mean(arr, axis=0),
        'std': np.std(arr, axis=0)
    }
    
    # Additional check: ensure no NaN in stats
    for key, val in stat.items():
        if np.any(np.isnan(val)):
            print(f"[ERROR] array_to_stats: {key} contains NaN after computation!")
            print(f"  Array shape: {arr.shape}")
            print(f"  {key}: {val}")
    
    return stat

def concatenate_normalizer(normalizers: list):
    scale = torch.concatenate([normalizer.params_dict['scale'] for normalizer in normalizers], axis=-1)
    offset = torch.concatenate([normalizer.params_dict['offset'] for normalizer in normalizers], axis=-1)
    input_stats_dict = dict_apply_reduce(
        [normalizer.params_dict['input_stats'] for normalizer in normalizers],
        lambda x: torch.concatenate(x,axis=-1))
    return SingleFieldLinearNormalizer.create_manual(
        scale=scale,
        offset=offset,
        input_stats_dict=input_stats_dict
    )

def get_action_normalizer(actions: np.ndarray, temporally_independent_normalization=False):
    assert not temporally_independent_normalization, "Not use temporally independent normalization now"
    assert len(actions.shape) == 2 or len(actions.shape) == 3
    if not temporally_independent_normalization:
        actions = actions.reshape(-1, actions.shape[-1])

    D = actions.shape[-1]
    print(f"[DEBUG] get_action_normalizer: action shape = {actions.shape}, D = {D}")
    
    # Check for NaN or Inf values
    if np.isnan(actions).any():
        print(f"[WARNING] Found NaN values in actions! Count: {np.isnan(actions).sum()}")
    if np.isinf(actions).any():
        print(f"[WARNING] Found Inf values in actions! Count: {np.isinf(actions).sum()}")
    
    if D == 3 or D == 4 or D == 6 or D == 8: # (x, y, z, gripper_width)
        normalizers = [get_range_normalizer_from_stat(array_to_stats(actions))]
    elif D == 9 or D == 10: # (x, y, z, rx1, rx2, rx3, ry1, ry2, ry3)
        normalizers = []
        normalizers.append(get_range_normalizer_from_stat(array_to_stats(actions[...,:3])))
        # don't normalize rotation
        normalizers.append(get_identity_normalizer_from_stat(array_to_stats(actions[...,3:9])))
        if D == 10:
            normalizers.append(get_range_normalizer_from_stat(array_to_stats(actions[...,9:])))
    elif D == 25:
        # For kinedex: 25-dim action (10 robot + 15 tactile)
        # Robot action (10-dim): xyz (3) + 6d rotation (6) + gripper (1)
        # Tactile embedding (15-dim): PCA-reduced tactile markers
        normalizers = []
        # normalize position (xyz)
        normalizers.append(get_range_normalizer_from_stat(array_to_stats(actions[...,:3])))
        # don't normalize rotation (6d)
        normalizers.append(get_identity_normalizer_from_stat(array_to_stats(actions[...,3:9])))
        # normalize gripper width
        normalizers.append(get_range_normalizer_from_stat(array_to_stats(actions[...,9:10])))
        # normalize tactile embedding (15-dim)
        normalizers.append(get_range_normalizer_from_stat(array_to_stats(actions[...,10:])))    
    elif D == 18 or D == 20:
        normalizers = []
        normalizers.append(get_range_normalizer_from_stat(array_to_stats(actions[...,:3])))
        # don't normalize rotation
        normalizers.append(get_identity_normalizer_from_stat(array_to_stats(actions[...,3:9])))
        normalizers.append(get_range_normalizer_from_stat(array_to_stats(actions[...,9:12])))
        # don't normalize rotation
        normalizers.append(get_identity_normalizer_from_stat(array_to_stats(actions[...,12:18])))
        if D == 20:
            normalizers.append(get_range_normalizer_from_stat(array_to_stats(actions[...,18:])))
    else:
        raise NotImplementedError

    normalizer = concatenate_normalizer(normalizers)
    return normalizer
